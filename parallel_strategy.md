## 模型并行
* 将模型按照Layer粒度切分为不同的Stage，并将其分配至不同的GPU中执行，以降低每张GPU卡中的模型显存占用，从而提高Batch Size。
* 增大Batch Size，使训练更加稳定，从而收敛效果更好。

## 流水并行
* 如果仅采用模型并行，则GPU卡间任务执行有依赖，因此同一时间只有一个GPU执行，其他GPU空闲，导致GPU利用率低。Whale流水并行中实现一个Mini-Batch对应一个Micro-Batch，同时可以训练多个Micro-Batch，不同GPU中可以同时执行流水的不同Stage，从而提高GPU利用率。

## 数据并行
* 受限于模型Layer总数和流水并行效率，模型并行和流水并行的混合并行策略不能无限地进行分布式扩展。在超大训练数据规模场景，还需要结合数据并行进行分布式扩展。
